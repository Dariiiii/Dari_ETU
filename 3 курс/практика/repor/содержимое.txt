

8ОПРЕДЕЛЕНИЯ, ОБОЗНАЧЕНИЯ И СОКРАЩЕНИЯЯП – язык программирования;IDE – Integrated Development Environment;ПО – программное обеспечение;HTTP – HyperText Transfer Protocol;HTML – HyperText Markup Language;URL – Uniform Resource Locator;CLF – Common Log Format;DBSCAN – Density-Based Spatial Clustering of Applications with Noise;BERT – Bidirectional Encoder Representations from Transformers;Лог - файл журнала с записями о событиях в хронологическом порядке.

9ВВЕДЕНИЕС каждым днем количество веб-серверов и их пользователей растет [1].В связи с этим возникает необходимость в эффективном анализе и обработкеданных журналов событий веб-серверов для обеспечения надежности и без-опасности веб-сервисов, а также для выявления и предотвращения возможныханомалий.Цель данной работы разработка модели классификации событий в жур-налах веб-серверов на основе методов машинного обучения.Задачи данной работы:1. Изучение и анализ существующих алгоритмов кластеризации.2. Разработка алгоритма предварительной обработки данных журналовдля повышения эффективности классификации.3. Создание и обучение модели классификации событий.4. Оценка эффективности разработанной модели на реальных данных.

Объектом исследования является модель для классификации журналоввеб серверов.Предметом исследования является алгоритм кластеризации и выявле-ния аномалий.Практическая значимость работы заключается в том, что разработан-ная модель классификации событий в журналах веб-серверов способствует ав-томатизации процессов обнаружения аномалий, что позволяет сократитьвремя на обработку инцидентов.





101 ОБЗОР ПРЕДМЕТНОЙ ОБЛАСТИ1.1 Основные теоретические положения

1.1.1 Работа веб-сервера

Веб-сервер — это ПО, обрабатывающее запросы к веб-страницам через Ин-тернет и предоставляющее HTTP-ответы, как правило, вместе с HTML-стра-ницей, изображением, файлом, медиа-потоком или другими данными. Он ра-ботает по следующему принципу:

 Получение запроса: Когда пользователь вводит URL веб-сайта в брау-зере или переходит по ссылке, браузер отправляет запрос на веб-сервер,на котором хранится сайт.

 Обработка запроса: Веб-сервер анализирует полученный запрос, опре-деляя, какую страницу или ресурс (например, изображение или доку-мент) необходимо предоставить.

 Поиск ресурса: Веб-сервер ищет запрашиваемый ресурс на своем храни-лище. Если ресурс требует дополнительной обработки (например, вы-полнения скриптов на стороне сервера), сервер выполняет необходимыедействия для генерации финального содержимого.

 Отправка ответа: После нахождения или генерации запрашиваемого ре-сурса, веб-сервер формирует ответ, который включает в себя статус(например, успешно или ошибка) и сам ресурс (HTML-страницу, изоб-ражение и т.д.).

11

 Отображение ресурса: Браузер пользователя получает ответ от веб-сер-вера, обрабатывает его и отображает содержимое страницы или сообще-ние об ошибке, если доступ к ресурсу не был получен.

Схема работы сервера изображена на рис. 1.

Рисунок 1 — Схема работы веб-сервера

1.1.2 Запросы к серверу

В протоколе HTTP предусмотрено большое количество методов с помо-щью которых можно совершать запросы. Но в повседневной практике исполь-зуется, как правило только три: GET, POST и HEAD, именно они и встреча-ются в наборе данных, который использовался для анализа событий журналавеб-сервера.

Ниже представлено краткое пояснение к запросам к веб-серверу( таб-лица 1).

Таблица 1 — Запросы к веб-серверу

12МетодПояснениеGETДанный метод используетсядля запроса содержимого указанногоресурса.HEADЗапрос HEAD аналогичен GET,но сервер в ответе отправляет толькозаголовки и статус, без тела ответа.Это полезно для извлечения метадан-ных, таких как тип содержимого илипоследняя дата модификацииPOSTЗапрос POST применяется дляотправки данных для обработки навеб-сервер. Это могут быть формыобратной связи, загрузка файлов, до-бавление комментариев на сайт.



1.1.3 Коды ответа HTTP

Коды ответа HTTP — это стандартизированные коды, которые веб-сер-веры используют для сообщения клиентам о результате их запросов. Коды от-вета подразделяются на несколько классов, каждый из которых имеет своюсферу применения.

Ниже представлено краткое пояснение к кодам ответа HTTP( таблица 2).Таблица 2 — Коды ответа HTTP.МетодПояснение

131xxИнформационные коды отве-тов. Пример: 100 Continue — клиентможет продолжать отправку за-проса.2xxКоды ответа, означающиеуспешное выполнение запроса. Пример: 200 OK — стандарт-ный ответ для успешныхHTTP-запросов. Пример: 201 Created — запросуспешен и в результате был со-здан новый ресурс.3xxКоды ответа, означающие необ-ходимость перенаправления на дру-гой ресурс или URL Пример: 301 MovedPermanently — ресурс оконча-тельно перемещен на новыйURL. Пример: 302 Found — ресурсвременно перемещен на другойURL.4xxЭти коды указывают на ошибкусо стороны клиента. Пример: 400 Bad Request —сервер не понимает запрос из-за неверного синтаксиса.

14 Пример: 401 Unauthorized —для доступа к запрашиваемомуресурсу требуется аутентифи-кация. Пример: 404 Not Found — сер-вер не может найти запрашива-емый ресурс.5xxЭти коды сообщают о пробле-мах на стороне сервера, которые онне смог обработать. Пример: 500 Internal ServerError — общая ошибка сервера,когда сервер сталкивается с си-туацией, которую он не знаеткак обработать. Пример: 503 Service Unavailable— сервер временно не досту-пен, обычно из-за перегрузкиили технического обслужива-ния.



1.1.4 Логи сервера Apache

Логи сервера Apache — это файлы журналов, в которые записываетсяинформация о всех запросах и действиях, происходящих на веб-сервере. Этиданные крайне важны для анализа трафика, отладки, мониторинга безопасно-сти и оптимизации работы сервера.



15Основные типы лог-файлов Apache:

Access Log (Журнал доступа): Содержит информацию о каждом запросек серверу. Здесь можно найти данные о времени запроса, IP-адресе клиента,методе HTTP, запрашиваемом URL, статусе HTTP ответа, размере ответа и ин-формацию о браузере пользователя (User-Agent).

Error Log (Журнал ошибок): Фиксирует ошибки, возникшие во время ра-боты сервера. Это могут быть проблемы с конфигурацией, недоступность фай-лов, проблемы с сетевыми соединениями и другие системные ошибки. Этотжурнал является основным инструментом для диагностики проблем на сер-вере.

Custom Logs (Пользовательские журналы): Apache позволяет настраи-вать логи для записи специфической информации в соответствии с потребно-стями администратора. Это может быть полезно для сбора конкретных данныхдля анализа.

Однако в данной работе для анализа журналов событий используетсятолько Access Log.В записи логов сервера Apache используется формат Common LogFormat (CLF)[4] или его расширения, такие как Combined Log Format.

Пример стандартной записи в Access Log в формате CLF изображён нарис. 2Рисунок 2 — Пример записи логов веб-сервераВ логах содержится следующая информация:

16

 IP адрес устройства с которого совершен запрос; Дата и время запроса; URL адрес к которому направлен запрос; Метод с помощью которого совершен запрос (GET, POST и т. д); Код ответа на совершенный запрос; Referer — адрес страницы с которой был совершен переход на текущую; User-Agent пользователя — идентификатор устройства и браузера.С помощью логов мы можем выявить множество метрик: На какие страницы чаще всего заходят пользователи; С каких устройств чаше всего заходят пользователи; Какие поисковые боты посещают сайт и какие страницы индексируют; Наличие на сайте несуществующих страниц, к которым тем не менее об-ращаются пользователи и, что наиболее важно поисковые боты; Наличие на сайте редиректов; Наличие на сайте критических ошибок 5xx.

1.2 Кластеризация объектов или кластерный анализ

1.2.1 Понятие кластеризации

Кластеризация (или кластерный анализ)[2]  представляет собой процессгруппировки набора элементов в группы, называемые кластерами. Целью яв-ляется собрать в одной группе элементы, которые между собой похожи, в товремя как элементы, принадлежащие к разным группам, должны максимальноотличаться друг от друга. Основное различие между кластеризацией и класси-фикацией заключается в том, что при кластеризации заранее не определеныконкретные группы, их выявление происходит в ходе выполнения алгоритма.



17Процесс кластерного анализа включает в себя несколько шагов:1. Выборка данных для кластеризации.

2. Определение набора переменных, по которым будет проводиться оценкаэлементов выборки. При необходимости осуществляется нормализацияданных.

3. Расчет значений меры сходства между элементами.

4. Применение специализированного метода кластерного анализа для фор-мирования групп похожих элементов(кластеров).

5. Визуализация и интерпретация полученных результатов кластеризации.На этапе анализа результатов может потребоваться доработка использу-емых метрик и методов кластеризации для достижения наилучших результа-тов.

1.2.2 Меры расстояний

Чтобы вычислять значения меры сходства между объектами  нужно со-ставить вектор характеристик для каждого объекта — как правило, это наборчисловых значений. Однако существуют также алгоритмы, работающие с ка-чественными (категорийными) характеристиками.

После того, как определён вектор характеристик, можно провести нор-мализацию, чтобы все компоненты давали одинаковый вклад при расчете«расстояния». В процессе нормализации все значения приводятся к некото-рому диапазону, например,[−1,1] или [0,1].Далее, для каждой пары объектов измеряется «расстояние» между ними —степень похожести. Существует множество метрик, чаще всего используются:

181. Евклидово расстояниеНаиболее распространенная функция расстояния. Представляет собойгеометрическим расстоянием в многомерном пространстве:

𝜌(𝑥, 𝑥′) = √∑(𝑥𝑖 − 𝑥𝑖′)2𝑚���𝑖



2. Квадрат евклидова расстояния

Применяется для придания большего веса более отдаленным друг от другаобъектам. Это расстояние вычисляется следующим образом:

𝜌(𝑥, 𝑥′) = ∑(𝑥𝑖 − 𝑥𝑖′)2𝑚���𝑖



3. Расстояние городских кварталов (манхэттенское расстояние)[9]

Это расстояние является средним разностей по координатам. В большинствеслучаев эта мера расстояния приводит к таким же результатам, как и для обыч-ного расстояния Евклида. Однако для этой меры влияние отдельных большихразностей (выбросов) уменьшается (т.к. они не возводятся в квадрат). Формуладля расчета манхэттенского расстояния:

𝜌(𝑥, 𝑥′) = ∑

𝑥𝑖 − 𝑥𝑖′

𝑚���𝑖



4. Расстояние Чебышева



19Это расстояние может оказаться полезным, когда нужно определить два объ-екта как «различные», если они различаются по какой-либо одной координате.Расстояние Чебышева вычисляется по формуле:

𝜌(𝑥, 𝑥′) = ∑ 𝑘���𝑎𝑥𝑚���𝑖(

𝑥𝑖 − 𝑥𝑖′

)

5. Степенное расстояние

Применяется в случае, когда необходимо увеличить или уменьшить вес, отно-сящийся к размерности, для которой соответствующие объекты сильно отли-чаются. Степенное расстояние вычисляется по следующей формуле:

𝜌(𝑥, 𝑥′) = √∑(𝑥𝑖 − 𝑥𝑖′)𝑝𝑚���𝑖𝑟



где 𝑟 и 𝑘��� – параметры, определяемые пользователем. Параметр 𝑘��� ответствененза постепенное взвешивание разностей по отдельным координатам, параметр𝑟 ответственен за прогрессивное взвешивание больших расстояний междуобъектами. Если оба параметра – 𝑟 и 𝑘��� — равны двум, то это расстояние сов-падает с расстоянием Евклида.

Выбор метрики полностью лежит на исследователе, поскольку резуль-таты кластеризации могут существенно отличаться при использовании разныхмер.

1.2.3 Классификация алгоритмов

1. Иерархические и плоские.

20

Иерархические алгоритмы (также называемые алгоритмами таксономии)строят не одно разбиение выборки на непересекающиеся кластеры, а системувложенных разбиений. Таким образом на выходе получается дерево кластеров,корнем которого является вся выборка, а листьями — наиболее мелкие кла-стера.Плоские алгоритмы строят одно разбиение объектов на кластеры.

2. Четкие и нечеткие.Четкие (или непересекающиеся) алгоритмы каждому объекту выборки ставятв соответствие номер кластера, таким образом каждый объект принадлежиттолько одному кластеру. Нечеткие (или пересекающиеся) алгоритмы каждомуобъекту ставят в соответствие набор вещественных значений, показывающихстепень отношения объекта к кластерам. В итоге каждый объект относится ккаждому кластеру с некоторой вероятностью.

1.2.4 Объединение кластеров

В случае использования иерархических алгоритмов необходимо решить,как объединять между собой кластера, как вычислять «расстояния» междуними. Существует несколько метрик:

1. Одиночная связь (расстояния ближайшего соседа)В этом методе расстояние между двумя кластерами определяется расстояниеммежду двумя наиболее близкими объектами (ближайшими соседями) в различ-ных кластерах. Результирующие кластеры имеют тенденцию объединяться вцепочки.

2. Полная связь (расстояние наиболее удаленных соседей)

21В этом методе расстояния между кластерами определяются наибольшим рас-стоянием между любыми двумя объектами в различных кластерах (т.е. наибо-лее удаленными соседями). Этот метод обычно работает очень хорошо, когдаобъекты происходят из отдельных групп. Если же кластеры имеют удлинен-ную форму или их естественный тип является «цепочечным», то этот методнепригоден.

3. Невзвешенное попарное среднееВ этом методе расстояние между двумя различными кластерами вычисляетсякак среднее расстояние между всеми парами объектов в них. Метод эффекти-вен, когда объекты формируют различные группы, однако он работает одина-ково хорошо и в случаях протяженных («цепочечного» типа) кластеров.

4. Взвешенное попарное среднееМетод идентичен методу невзвешенного попарного среднего, за исключениемтого, что при вычислениях размер соответствующих кластеров (то есть числообъектов, содержащихся в них) используется в качестве весового коэффици-ента. Поэтому данный метод должен быть использован, когда предполагаютсянеравные размеры кластеров.

5. Невзвешенный центроидный методВ этом методе расстояние между двумя кластерами определяется как расстоя-ние между их центрами тяжести.

6. Взвешенный центроидный метод (медиана)Этот метод идентичен предыдущему, за исключением того, что при вычисле-ниях используются веса для учета разницы между размерами кластеров. По-этому, если имеются или подозреваются значительные отличия в размерахкластеров, этот метод оказывается предпочтительнее предыдущего.



221.2.5 Обзор алгоритмов кластеризации

 Алгоритмы иерархической кластеризации[5]

Среди алгоритмов иерархической кластеризации выделяются два основ-ных типа: восходящие и нисходящие алгоритмы. Нисходящие алгоритмы ра-ботают по принципу «сверху-вниз»: в начале все объекты помещаются в одинкластер, который затем разбивается на все более мелкие кластеры. Более рас-пространены восходящие алгоритмы, которые в начале работы помещаюткаждый объект в отдельный кластер, а затем объединяют кластеры во все бо-лее крупные, пока все объекты выборки не будут содержаться в одном кла-стере. Таким образом строится система вложенных разбиений. Результаты та-ких алгоритмов обычно представляют в виде дерева – дендрограммы. Класси-ческий пример такого дерева – классификация животных и растений.

Для вычисления расстояний между кластерами чаще все пользуютсядвумя расстояниями: одиночной связью или полной связью .

К недостатку иерархических алгоритмов можно отнести систему пол-ных разбиений, которая может являться излишней в контексте решаемой за-дачи.

 Алгоритмы квадратичной ошибки[6]

Задачу кластеризации можно рассматривать как построение оптимальногоразбиения объектов на группы. При этом оптимальность может быть опреде-лена как требование минимизации среднеквадратической ошибки разбиения:



23𝑒2(𝑋, 𝐿) = ∑ ∑ ‖𝑥𝑖(𝑖���) − 𝑐𝑖���‖2𝑚���𝑗𝑖=0𝑖���𝑖���=0



где 𝑐𝑖��� — «центр масс» кластера j (точка со средними значениями характери-стик для данного кластера).

Алгоритмы квадратичной ошибки относятся к типу плоских алгоритмов. Са-мым распространенным алгоритмом этой категории является метод k-средних.Этот алгоритм строит заданное число кластеров, расположенных как можнодальше друг от друга. Работа алгоритма делится на несколько этапов:

1. Случайно выбрать k точек, являющихся начальными «центрами масс»кластеров.

2. Отнести каждый объект к кластеру с ближайшим «центром масс».

3. Пересчитать «центры масс» кластеров согласно их текущему составу.

4. Если критерий остановки алгоритма не удовлетворен, вернуться кпункту 2.

В качестве критерия остановки работы алгоритма обычно выбирают мини-мальное изменение среднеквадратической ошибки. Так же возможно останав-ливать работу алгоритма, если на шаге 2 не было объектов, переместившихсяиз кластера в кластер.

К недостаткам данного алгоритма можно отнести необходимость задавать ко-личество кластеров для разбиения.



24 Нечеткие алгоритмы

Наиболее популярным алгоритмом нечеткой кластеризации является алго-ритм c-средних (c-means). Он представляет собой модификацию метода k-средних. Шаги работы алгоритма:

1. Выбрать начальное нечеткое разбиение 𝑘��� объектов на 𝑘 кластеров путемвыбора матрицы принадлежности 𝑈 размера 𝑘���𝑥𝑘.

2. Используя матрицу 𝑈, найти значение критерия нечеткой ошибки:

𝐴���2(𝑋, 𝑈) = ∑∑𝑈𝑖𝑖���𝐾𝑖���=1𝑁𝑖=1‖𝑥𝑖(𝑖���) − 𝑐𝑖���‖2,

где 𝑐𝑖��� — «центр масс» нечеткого кластера 𝑘:

𝑐𝑖��� = ∑𝑈𝑖���𝑁𝑖=1𝑥𝑖.

3. Перегруппировать объекты с целью уменьшения этого значения крите-рия нечеткой ошибки.4. Возвращаться в пункт 2 до тех пор, пока изменения матрицы 𝑈 не станутнезначительными.

Этот алгоритм может не подойти, если заранее неизвестно число кластеров,либо необходимо однозначно отнести каждый объект к одному кластеру.

 DBSCAN (Density-Based Spatial Clustering of Applications with Noise)[3]DBSCAN кластеризует точки, основываясь на их плотности расположения.Этот алгоритм способен находить кластеры произвольной формы и хорошо

25работает с данными, содержащими шум и выбросы. DBSCAN определяет кла-стеры как области высокой плотности, разделенные областями низкой плот-ности, и не требует предварительного определения количества кластеров.

Этот алгоритм наиболее подходит для данной задачи, поскольку способеннаходить выбросы, в нашем случае аномалии, также не надо задавать количе-ство кластеров заранее, алгоритм сам определяет их количество по данным.

 Алгоритмы, основанные на теории графов[7]

Суть таких алгоритмов заключается в том, что выборка объектов представля-ется в виде графа 𝐴��� = (𝑈���, 𝐴���), вершинам которого соответствуют объекты, аребра имеют вес, равный «расстоянию» между объектами. Достоинством гра-фовых алгоритмов кластеризации являются наглядность, относительная про-стота реализации и возможность внесения различных усовершенствований,основанные на геометрических соображениях. Основными алгоритмам явля-ются алгоритм выделения связных компонент, алгоритм построения мини-мального покрывающего (остовного) дерева и алгоритм послойной кластери-зации.

 Алгоритм выделения связных компонент

В алгоритме выделения связных компонент задается входной параметр 𝑅 и вграфе удаляются все ребра, для которых «расстояния» больше 𝑅. Соединен-ными остаются только наиболее близкие пары объектов. Смысл алгоритма за-ключается в том, чтобы подобрать такое значение 𝑅, лежащее в диапазон всех«расстояний», при котором граф «развалится» на несколько связных компо-нент. Полученные компоненты и есть кластеры.



26Для подбора параметра 𝑅 обычно строится гистограмма распределений попар-ных расстояний. В задачах с хорошо выраженной кластерной структурой дан-ных на гистограмме будет два пика – один соответствует внутрикластернымрасстояниям, второй – межкластерным расстояния. Параметр 𝑅 подбираетсяиз зоны минимума между этими пиками. При этом управлять количеством кла-стеров при помощи порога расстояния довольно затруднительно.

 Алгоритм минимального покрывающего дерева[8][10]

Алгоритм минимального покрывающего дерева сначала строит на графе ми-нимальное покрывающее дерево, а затем последовательно удаляет ребра снаибольшим весом. На рисунке изображен пример минимального покрываю-щего дерева, полученного для девяти объектов(рис. 3).

Рисунок 3 — Минимальное покрывающее дерево для девяти объектов

Путём удаления связи, помеченной 𝐴���𝐴���, с длиной равной 6 единицам (ребро смаксимальным расстоянием), получаем два кластера: 𝐴, 𝐴���, 𝐴��� и 𝐴���, 𝐴���, 𝐴���, 𝐴���, 𝐴���, 𝐴���.

27Второй кластер в дальнейшем может быть разделён ещё на два кластера путёмудаления ребра 𝐴���𝐴���, которое имеет длину, равную 4.5 единицам.





28 Послойная кластеризация

Алгоритм послойной кластеризации основан на выделении связных ком-понент графа на некотором уровне расстояний между объектами (вершинами).Уровень расстояния задается порогом расстояния 𝑐. Например, если расстоя-ние между объектами 0 ≤ 𝑘���(𝑥, 𝑥′) ≤ 1 , то 0 ≤ 𝑐 ≤ 1.

Алгоритм послойной кластеризации формирует последовательностьподграфов графа 𝐴���, которые отражают иерархические связи между класте-рами:

𝐴���0 ⊆ 𝐴���1 ⊆. . . ⊆ 𝐴���𝑚

где 𝐴���𝑡 = (𝑈���, 𝐴���𝑡) — граф на уровне с𝑡,𝐴���𝑡 = {𝑒𝑖𝑖��� ∈ 𝐴���: 𝑘���𝑖𝑖��� ≤ 𝑐𝑡},с𝑡 – 𝑡-ый порог расстояния,𝑘��� – количество уровней иерархии,𝐴���0 = (𝑈���, 𝑘���), 𝑘��� – пустое множество ребер графа, получаемое при 𝑡0 = 1,𝐴���𝑚 = 𝐴���, то есть граф объектов без ограничений на расстояние (длинуребер графа), поскольку 𝑡𝑚 = 1.

Посредством изменения порогов расстояния {с0, … , с𝑚}, где 0 = с0 <с1 < ⋯ < с𝑚 = 1, возможно контролировать глубину иерархии получаемыхкластеров. Таким образом, алгоритм послойной кластеризации способен со-здавать как плоское разбиение данных, так и иерархическое.





291.2.6 Сравнение алгоритмов

В таблице представлена вычислительная сложность алгоритмов(таблица3)

Таблица 3 — Вычислительная сложность алгоритмов.Алгоритм кластеризацииВычислительная сложностьИерархический𝑂(𝑘���2)k-средних𝑂(𝑘���𝑘𝑘���), где 𝑘 – число кластеров, 𝑘��� –число итерацийc-среднихВыделение связных компонентзависит от алгоритмаМинимальное покрывающее дерево 𝑂(𝑘���: 2𝑘���𝑘���𝑔𝑘���)Послойная кластеризация𝑂(𝑘���𝑎𝑥(𝑘���, 𝑘���)), где 𝑘��� <𝑘��� (𝑘��� − 1) 2⁄

В таблице представлено сравнение алгоритмов(таблица 4)Таблица 4 — Сравнительная таблица алгоритмов.АлгоритмкластеризацииФорма кла-стеровВходныеданныеРезультатыИерархиче-скийПроизволь-наяЧисло кла-стеров или порограсстояния дляусечения иерар-хииБинарноедерево кластеровk-среднихГиперсфераЧисло кла-стеровЦентры кла-стеровc-среднихГиперсфераЧисло кла-стеров, степеньЦентры кла-стеров, матрица

30нечеткостипринадлежностиВыделениесвязных компо-нентПроизволь-наяПорог рас-стояния RДревовид-ная структуракластеровМинималь-ное покрывающеедеревоПроизволь-наяЧисло кла-стеров или порограсстояния дляудаления реберДревовид-ная структуракластеровПослойнаякластеризацияПроизволь-наяПоследова-тельность пороговрасстоянияДревовид-ная структуракластеров с раз-ными уровнямииерархии



1.2.Выводы

Выбор алгоритма кластеризации DBSCAN для анализа событий в жур-налах веб-серверов обусловлен рядом его преимуществ перед другими алго-ритмами. Во-первых, DBSCAN отлично подходит для выявления аномалий,так как он способен определить и исключить отдаленные точки, которые непринадлежат ни одному кластеру, рассматривая их как выбросы. Это особенноценно в контексте безопасности веб-серверов, где такие аномалии могут ука-зывать на нестандартное или подозрительное поведение.

Также, DBSCAN не требует предварительного указания количества кла-стеров, что делает его гибким в работе с данными, структура которых заранеенеизвестна. Это позволяет алгоритму адаптироваться к данным различнойприроды и выявлять скрытые структуры без необходимости их предваритель-ного определения.

31

Помимо этого, DBSCAN устойчив к шуму и способен выделять кла-стеры произвольной формы, что делает его применимым к разнообразнымнаборам данных, включая те, которые содержат сложные и пересекающиесяструктуры.Кроме того, DBSCAN эффективен в вычислительном плане, особеннокогда используется в сочетании со структурами данных индексации, что поз-воляет сократить время обработки даже больших объемов данных.

Таким образом, DBSCAN является мощным инструментом для класте-ризации данных журналов веб-серверов, обеспечивая высокое качество обна-ружения аномалий и гибкость в работе с различными типами данных.

322 ВЫБОР МЕТОДА РЕШЕНИЯ

2.1 Постановка задачи

Необходимо разработать модель для кластеризации логов веб-серверовс целью выявления аномальных событий. Модель должна быть способна об-рабатывать и анализировать записи журналов веб-серверов, выделяя из нихстатистически значимые кластеры, характеризующие типичное поведение си-стемы, а также идентифицировать отклонения от нормы, которые могут сви-детельствовать о потенциальных угрозах или нештатных ситуациях.

2.2 Сбор и предобработка данных

Необходимо организовать сбор данных из журналов веб-серверов, ихочистку и нормализацию для последующего использования в модели класте-ризации. Это включает удаление нерелевантной информации, преобразованиетекстовых данных в числовой формат и обработку пропущенных значений.

2.3 Исследование и выбор метода кластеризации

Также необходимо было провести анализ существующих алгоритмовкластеризации для определения наиболее подходящего под задачи работы.Нужно учитывать способность алгоритма обрабатывать большие объемы дан-ных, его устойчивость к шуму и способность выявлять аномалии.

2.4 Разработка модели

Далее нужно разработать модель, которая будет принимать на вход за-писи журналов, обрабатывать их и формировать кластеры, представляющие

33типовые сценарии работы веб-сервера. Модель должна быть способна адапти-роваться к изменениям в данных и обновлять кластеры со временем.

2.5 Выявление аномалий

Необходимо интегрировать механизмы для определения и отслеживанияаномальных событий, которые не соответствуют ни одному из существующихкластеров. Это включает разработку правил или использование статистиче-ских методов для выявления потенциальных угроз.

Тестирование и валидация модели

Необходимо провести проверку эффективности модели на тестовых иреальных данных, оценка точности кластеризации и способности модели к де-тектированию аномалий. В силу отсутствия заранее размеченных данных,оценка качества кластеризации и способности модели к детектированию ано-малий будет иметь субъективный характер.



343 ОПИСАНИЕ МЕТОДА РЕШЕНИЯ Необходимо провести проверку эффективности модели на тесто-вых и реальных данных, оценка точности кластеризации и способ-ности модели к детектированию аномалий. В силу отсутствия V ss3.1 Генерация набора событий журнала веб-сереров

В процессе разработки модели классификации событий в журналах веб-серверов возникла необходимость в создании набора данных для начальныхэтапов обучения модели. Из-за отсутствия доступа к реальным журналам веб-сервера было принято решение о генерации искусственного набора данных,соответствующего формату CLF.

Для создания искусственных записей журнала была использована биб-лиотека faker, предназначенная для генерации случайных данных в языке про-граммирования Python. Эта библиотека позволила сформировать реалистич-ные IP-адреса и URL-адреса, имитируя потенциальные запросы пользователейк веб-серверу. Поле user-agent было сгенерировано на основе десяти различ-ных заготовленных значений, которые отражали распространенные браузерыи операционные системы.

Остальные поля журнала, такие как дата и время запроса, статус ответасервера и размер передаваемого контента, также создавались случайным об-разом, обеспечивая разнообразие в генерируемом наборе данных. Каждая за-пись в журнале формировалась путем случайного выбора значений для каж-дого поля, соблюдая структуру и формат CLF.



35Однако в ходе последующего тестирования модели выявилось, что ис-пользование сгенерированных данных приводит к неудовлетворительным ре-зультатам. Модель, обученная на искусственных данных, не смогла адекватносправляться с задачей классификации и выявления аномалий при работе с ре-альными журналами веб-серверов. Анализ показал, что отсутствие реалистич-ных шаблонов поведения и взаимосвязей в сгенерированных данных не поз-воляло модели корректно обобщать информацию и выявлять значимые анома-лии.

В связи с этим было принято решение отказаться от использования ис-кусственно сгенерированных данных и перейти к работе с реальными журна-лами веб-серверов, что позволило значительно улучшить качество и точностьклассификации модели.

3.2 Предварительная обработка данных

Был проведён отбор необходимых данных из общего множества запи-сей журнала и удаление тех полей, которые не несут значимой информациидля анализа.

В рамках предварительной обработки было решено оставить следующиеполя, которые считаются наиболее важными для дальнейшего анализа и выяв-ления аномалий:

 Коды ошибок (Status Codes): Позволяют определить успешность или не-удачу запроса и являются ключевыми для выявления проблем на веб-сервере. Время запроса (Timestamp): Важно для анализа паттернов активности иидентификации нестандартного поведения, например, внезапныхвсплесков трафика.

36 URL (Uniform Resource Locator): Адрес запрашиваемого ресурса можетуказывать на целевые страницы атак или на необычные пути доступа. User-Agent: Информация о браузере и операционной системе пользова-теля помогает выявить подозрительные или устаревшие клиенты, потен-циально уязвимые для эксплуатации. ENDPOINT: Конкретный ресурс на сервере, к которому был выполнензапрос, может выявить необычные или подозрительные пути доступа. SIZE OF RESPONSE: Размер ответа сервера может указывать на не-обычно большие или маленькие ответы, что также может быть призна-ком аномалии.

Выбор этих полей обусловлен тем, что статистическое отклонение поним может служить индикатором аномального поведения. Например, нестан-дартный размер ответа сервера или неожиданный всплеск в определенные пе-риоды времени может указывать на попытки взлома, DDoS-атаки или другиевиды аномалий. Анализ кодов ошибок может выявить не только техническиепроблемы, но и целенаправленные атаки на веб-сервер.

Таким образом, предварительная обработка данных заключается в ис-ключении из рассмотрения нерелевантных полей и фокусировке внимания натех атрибутах, которые могут предоставить наиболее ценную информациюдля обнаружения и анализа аномальных событий. Это создает основу для бо-лее эффективной и целенаправленной работы модели кластеризации и класси-фикации событий.

3 Описание алгоритма







37Так как основной задачей является разработка модели для кластериза-ции с выявлением аномалий, для достижения поставленной цели был выбраналгоритм DBSCAN, который является одним из наиболее подходящих мето-дов для работы с данными такого типа.

Алгоритм DBSCAN начинает свою работу с выбора произвольной точкииз набора данных и создания вокруг неё области с заданным радиусом, кото-рый называется эпсилон-окрестностью. Если в этой окрестности обнаружива-ется количество точек, превышающее или равное минимально заданному по-рогу (minPts), то исходная точка классифицируется как корневая, что служитсигналом к формированию нового кластера.Затем алгоритм переходит к поиску соседних точек. Если в эпсилон-окрестности точки находится меньше, чем minPts соседей, но среди них естьхотя бы одна корневая точка, эта точка помечается как пограничная. Погра-ничные точки не могут формировать новые кластеры, но могут быть частьюуже существующих кластеров.Все оставшиеся точки, которые не подпадают под критерии корневыхили пограничных, считаются выбросами. Они не включаются в кластеры и мо-гут быть интерпретированы как аномалии или шум в данных.Когда две корневые точки оказываются в пределах эпсилон-окрестностидруг от друга, они объединяются в один кластер. Это свойство позволяет кла-стерам формироваться и расти, поглощая новые корневые точки и их погра-ничные соседи.Пограничные точки присоединяются к тем кластерам, к которым при-надлежат корневые точки в их окрестности. Таким образом, они служат своегорода мостом, связывающим близлежащие кластеры.Процесс кластеризации завершается, когда все точки данных либо вклю-чены в кластеры, либо классифицированы как выбросы, и не остаётся ни одной

38точки, которую можно было бы добавить к существующим кластерам. Это га-рантирует, что каждая точка будет рассмотрена и получит своё место в общейструктуре данных.







3.3.2  Векторизация TF-IDF

Для преобразования текстовых полей журналов в числовые векторы, ко-торые могут быть использованы в кластеризации DBSCAN, применяется ме-тод TF-IDF. Этот метод векторизации оценивает важность слова в контекстедокумента относительно всего корпуса документов. Term Frequency (TF) из-меряет частоту слова в документе, а Inverse Document Frequency (IDF) умень-шает вес слов, которые встречаются очень часто и поэтому могут быть менееинформативными. Произведение TF и IDF дает веса словам, которые помо-гают выделить наиболее значимые термины для каждого документа.

Векторизация TF-IDF была реализована с использованием библиотекиScikit-learn[11], которая предоставляет инструменты для преобразования тек-стовых данных в формат, удобный для анализа. Полученные векторы TF-IDFзатем использовались в качестве входных данных для алгоритма DBSCAN,позволяя модели эффективно кластеризовать записи журналов и выявлять ано-малии на основе анализа текстового содержимого.

3.3.3  Векторизация BERT



Также использовалась векторизация текстовых полей журналов веб-сер-веров с помощью модели BERT[12], которая была доработана на данных фай-лов журналов веб-серверов. В отличие от  TF-IDF, данная модель использует

39нейронную сеть, состоящую из множества слоев, также учитывает расположе-ние слова в текстовом поле и выдаёт разные векторы для одного и того жеслова в зависимости от контекста. Например для поля user-agent, модель BERTмогла выделить кластеры по платформам, которые использовали пользова-тели, а также находила поисковых роботов, являющихся составной частью по-исковой системы yandex.



404 АНАЛИЗ ПОЛУЧЕННОГО РЕШЕНИЯ

4.1 Анализ решения, используя генерируемые данныеИспользование сгенерированных данных для анализа решения предоста-вило начальное понимание работы модели кластеризации. Эти данные былисозданы таким образом, чтобы имитировать различные типы событий в жур-налах веб-серверов, включая нормальные запросы и потенциальные аномалии.Однако при анализе результатов выяснилось, что модель, обученная и проте-стированная на таких данных, не обладает достаточной точностью разбиенияна кластеры.При оценке точности кластеризации, проведенной на основе сгенериро-ванных данных, столкнулись с субъективностью оценки. В отсутствие чёткоопределённых критериев и методов для точного выявления кластеров и ано-малий, оценка эффективности модели не может быть полностью объективной.В частности, для генерируемых данных было замечено, что записи журналоввеб-серверов группируются в 10 кластеров в зависимости от поля user-agent.Учитывая, что в искусственном наборе данных присутствует только 10 уни-кальных значений user-agent, такое разделение не отражает реальную слож-ность и многообразие поведения пользователей веб-сервера.Это наблюдение подтверждает, что кластеризация, основанная исклю-чительно на ограниченном числе уникальных значений user-agent, не являетсяоптимальной. Такой подход может привести к излишней генерализации и иг-норированию других важных аспектов данных, таких как временные пат-терны, коды состояния HTTP и размеры ответов, которые могут предоставитьболее глубокое понимание поведения системы и потенциальных угроз.Ниже представлена визуализация в трехмерном пространстве кластер-ного анализа искусственных данных, которые разбиты на 10 кластеров(рис. 4)

41

Рисунок 4 — визуализация кластерного анализа искусственных данных

2 Анализ решения, используя реальные данныеПереход к анализу решения на основе реальных данных журналов веб-серверов позволил значительно улучшить качество модели кластеризации. Ре-альные данные обеспечили более точное и всестороннее представление о по-ведении системы, включая различные виды запросов и потенциальные угрозы.Ниже представлена визуализация в трехмерном пространстве кластер-ного анализа реальных данных, которые разбиты уже на 20 кластеров(рис. 5)



42

Рисунок 5 — визуализация кластерного анализа реальных данных





435 Обеспечение качества разработки, продукции, программного про-дукта5.1 Определение потребителейПотребителями разработанной системы могут быть: Системные администраторы: Используют систему для мониторинга ианализа событий веб-серверов, управления логами и выявления техни-ческих проблем, что помогает в обеспечении стабильности и доступно-сти веб-сервисов. Специалисты по информационной безопасности: Применяют системудля обнаружения и реагирования на подозрительную активность и по-тенциальные угрозы безопасности, такие как вторжения или злоупо-требления, что повышает уровень защиты данных и инфраструктуры. Аналитики данных: Используют систему для извлечения значимых ин-сайтов из данных журналов, таких как модели поведения пользователейи трафика, что способствует лучшему пониманию потребностей пользо-вателей и оптимизации веб-контента. Разработчики веб-приложений: Интересуются системой как инструмен-том для отслеживания ошибок и недочетов в работе веб-приложений, атакже для тестирования новых функций и изменений в коде. Управляющий персонал IT-департаментов: Могут использовать системудля стратегического планирования и оптимизации ресурсов, а также дляобеспечения соответствия требованиям нормативно-правовых актов пообработке и хранению данных.Эти группы потребителей могут пользоваться системой для улучшениякачества своей работы, повышения эффективности процессов, снижения

44рисков и обеспечения более высокого уровня удовлетворенности конеч-ных пользователей.

 5.2 Функции продукцииДля того, чтобы ответить на вопрос, какие функции имеет разработан-ный продукт, необходимо ввести определение функции изделия или услуги.Функции изделия или услуги – это требования и ожидания потребителя, кото-рые могут быть установлены, предполагаются или являются обязательными.Функциональность разработанного программного продукта должна со-ответствовать требованиям потребителей. Для модели классификации собы-тий это включает в себя: Автоматическую обработку и анализ больших объемов данных журна-лов. Высокую точность классификации событий для минимизации ложныхсрабатываний. Гибкость в настройке параметров для адаптации к специфике различныхвеб-серверов. Интеграцию с существующими системами мониторинга и управления.5.3 Качество и характеристикиДля обеспечения качества разрабатываемого курса был проведен обзорстандартов, протоколов, отраслевых требований и современных лучших прак-тик, нужных в разработке. При этом качество – степень соответствия совокуп-ности присущих характеристик объекта требованиям (согласно ГОСТ Р ИСО9000-2015).

45Знание протоколов, стандартов и пр. позволяет разработчикам обеспе-чить соответствие курса современным требованиям, повысить эффективностьи удобство использования, улучшить качество курса.Анализ функциональных требований к разработке отражен в таблице(таблица 5).Таблица 5 — Функциональные тербованияФункции по группам

ИсточникТребованиеУдовлетворенностьГОСТ Р ИСО/МЭК25010-2015Модель должна клас-сифицировать записи жур-нала веб-сервера, основыва-ясь на статистических пока-зателях конкретного жур-нала веб-сервера.ИзучаемостьГОСТ Р ИСО/МЭК25010-2015Модель должнапредоставлять возможностьвизуализации результатовкластеризации.ПолноценностьГОСТ Р ИСО/МЭК25010-2015Модель должна обес-печивать возможность выяв-ления аномалий.ДоступностьГОСТ Р ИСО/МЭК25010-2015Модель должна обес-печить возможность класте-ризовать записи любых жур-налов веб-серверов.КонфиденциальностьГОСТ Р ИСО/МЭК25010-2015Доступ к результатамработы модели может бытьпредоставлен только адми-нистраторам веб-серверов.Документация и от-четностьГОСТ Р ИСО/МЭК25010-2015Ведение документа-ции и составление отчетов о

46процессе кластеризации за-писей журналов веб-серве-ров для последующего ана-лиза и использования в прак-тических целях





5.4 Измерение характеристик качества. Операциональное опреде-ление

Операциональное определение (ОО) – это уточнение значения того илииного термина применительно к данной системе, находящейся в конкретныхусловиях и для людей, в ней задействованных.ОО необходим для уменьшения случаев разночтения и неоднозначностипри общении между людьми, задействованными в системе, а также для болееточного определения целей и задач, которые необходимо достичь.ОО должно содержать как минимум три компоненты:1. Требования или стандарт, относительно которого оценивается результатизмерения или испытания (критерий).2. Метод испытания или процедура измерения свойства объекта (тест)3. Процедура принятия решения (анализ), которое показывает, соответ-ствует ли результат испытания стандарту.4. Операциональные определения для разработанного курса отражены втаблице (таблица 6).Таблица 6 — Операциональные определения.

ТребованиеТестРешение (правило)ХарактеристикаМетод измеренияСоответствиеЧастичное соответ-ствиеНесоответствиеМодель должна выяв-лять заведомо ано-мальные записиПроцент выявленныханомалий от общегочислаПодсчёт количества выяв-ленных аномалий относи-тельно общего количествазаведомо аномальных за-писей.95% или вышеОт 60% до 95%Ниже 60%Разбиение записейжурнала веб-серверана кластеры должнобыть достаточно ин-формативным дляанализаКоличество кластерови их объёмСубъективная визуальнаяпроверка количества кла-стеров, а также их напол-ненияРазбиение накластеры и выяв-ление аномалийсодержит полнуюинформацию дляанализа журналавеб-сервераРазбиение на кла-стеры и выявлениеаномалий содержитчастичную информа-цию для анализа жур-нала веб-сервераНа основе разбиениязаписей журнала веб-сервера на кластеры ивыявленных аномалийневозможно сделатьполезных выводов

48По итогам рассмотрения операциональных было определено, что разра-ботанный курс удовлетворяет, описанным требованиям, однако существуюттакже предложения по улучшению продукта, которые сформулированы в таб-лице (таблица 7).Таблица 7 — Предложения по улучшению продукта.ТребованиеАнализ те-кущего состояния

Возможныепричины невыполне-ния критерияПредложениепо улучшениюТочностьклассификацииТекущая точ-ность классификациисоответствует стан-дартам, но имеютсяслучаи ложных сра-батываний.Недостаточ-ная предварительнаяобработка данных иограниченное коли-чество обучающихпримеров.

Улучшить ал-горитмы предвари-тельной обработкиданных, увеличить идиверсифицироватьнабор данных дляобучения.Удобство ис-пользованияПользователисообщают о сложно-сти в освоении си-стемы.Недостаточноинтуитивно понят-ный интерфейс и от-сутствие подробнойдокументации.Разработатьболее удобный поль-зовательский интер-фейс и предоставитьобширную докумен-тацию и обучающиематериалы.



5.5 Выводы

Были определены потребители продукта, а также описаны ключевыефункции конечного продукта. Осуществлен обзор существующих стандартов,отраслевых требований и современных лучших практик, необходимых в раз-работке. По итогам обзора сформулированы функциональные требования кразработанной модели. Описаны операциональные определения, характерные

49для модели классификации записей журналов веб-серверов и выявления ано-малий. Сделан вывод о том, что разработанная модель удовлетворяет описан-ным требованиям, а также сформулировано предложение по дальнейшемуулучшению модели.



50ЗАКЛЮЧЕНИЕБыл проведен тщательный анализ существующих алгоритмов кластери-зации, что позволило оценить их применимость для работы с журналами веб-серверов и выбрать наиболее эффективные в соответствии с задачами класси-фикации событий.Разработанный алгоритм предварительной обработки данных оказалсянеотъемлемой частью исследования, поскольку он значительно повысил каче-ство и точность последующей классификации.Обработка включала в себя очистку данных, нормализацию, а также вы-бор и преобразование признаков, что создало надежную основу для обучениямодели.Созданная модель классификации событий была обучена на реальныхданных. Она продемонстрировала способность  различать типы событий, атакже выделять среди них аномалии.Таким образом, результаты данной работы могут быть использованы дляанализа событий журналов веб-серверов.



51СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ1.W3Techs[Электронныйресурс].URL:https://w3techs.com/technologies/overview/web_server (дата обращения:03.04.2024).2.Воронцов К. В. Лекции по алгоритмам кластеризации и многомерногошкалирования //М.: МГУ. – 2007.3.Ester M. et al. A density-based algorithm for discovering clusters in large spa-tial databases with noise //kdd. – 1996. – Т. 96. – №. 34. – С. 226-231.4.ApacheDocumentation[Электронныйресурс].URL:https://httpd.apache.org/docs/trunk/logs.html (дата обращения: 03.05.2024).5.Zhao Y., Karypis G., Fayyad U. Hierarchical clustering algorithms for docu-ment datasets //Data mining and knowledge discovery. – 2005. – Т. 10. – С.141-168.6.Pramanik S., Chandra M. G. Quantum-assisted graph clustering and quadraticunconstrained d-ary optimisation //arXiv preprint arXiv:2004.02608. – 2020.7.Pourasghar B. et al. A graph-based clustering algorithm for software systemsmodularization //Information and Software Technology. – 2021. – Т. 133. –С. 106469.8.Grygorash O., Zhou Y., Jorgensen Z. Minimum spanning tree based clusteringalgorithms //2006 18th IEEE International Conference on Tools with Artifi-cial Intelligence (ICTAI'06). – IEEE, 2006. – С. 73-81.9.Domański Z., Kęsy J. Distribuition of Manhattan distance in square and trian-gular lattices //Scientific Research of the Institute of Mathematics and Com-puter Science. – 2005. – Т. 4. – №. 1. – С. 34-37.10.Jain A. K., Murty M. N., Flynn P. J. Data clustering: a review //ACM compu-ting surveys (CSUR). – 1999. – Т. 31. – №. 3. – С. 264-323.11.Scikit-learn TfidfVectorizer [Электронный ресурс]. URL: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html (дата обращения: 03.05.2024).

5212.Bert base cased finetuned log parser [Электронный ресурс]. URL:https://huggingface.co/Slavka/bert-base-cased-finetuned-log-parser-winlogbeat_nowhitespace (дата обращения: 05.05.2024).



53ПРИЛОЖЕНИЕ АНазвание файла: ClusterLog.pyfrom sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.cluster import DBSCAN, OPTICSimport pandas as pdimport scipy.sparsefrom sklearn.decomposition import TruncatedSVDimport matplotlib.pyplot as pltimport plotlyimport plotly.express as pximport csv

file2 = open("/content/apache_logs.csv", "w")writer = csv.writer(file2)head = ["IP", "DATE", "REQUEST", "ENDPOINT", "STATUSCODE", "SIZEOF RESPONSE", "FAKE URL", "USER AGENT", "BYTES TRANSFERRED"]writer.writerow(head)

with open("/content/apache_logs.txt", "r") as file1:for line in file1:IP = line.split(" ")[0]pos1 = line.find("[")+1pos2 = line.find("]")DATE = line[pos1:pos2]row = [IP, DATE, "-", "-", "-", "-", "-", "-", "-"]writer.writerow(row)

file2.close()parser = pd.read_csv("/content/apache_logs.csv")

data_csv = pd.read_csv("/content/logfiles.csv")data_csv_clean = data_csv.drop(["DATE", "ENDPOINT"], axis=1)data_csv_clean = data_csv_clean[:1000]data_csv_clean_string = data_csv_clean.to_string(header=False, in-dex=False)data_csv_clean_list = data_csv_clean_string.split("\n")

with open("/content/apache_logs.txt", "r") as f:

54data = f.readlines()data = data[:1000]vectorizer = TfidfVectorizer()X = vectorizer.fit_transform(data)clustering = DBSCAN(eps=0.02, min_samples=3, metric= "cosine")labels = clustering.fit_predict(X)pca = TruncatedSVD(n_components=3)X_downsample = pca.fit_transform(X)df = pd.DataFrame(data = {"x": X_downsample[:, 0],"y": X_downsample[:, 1],"z": X_downsample[:, 2],"color": clustering.labels_,"text": data})fig = px.scatter_3d(df, x="x", y="y", z="z", color="color",size=[1] * len(df), hover_data="text", opacity=1)fig.show()df[df["color"] == -1]["text"].to_csv("/content/cluster_all_anom-aly.csv", index=False)print(pca.explained_variance_ratio_)print(pca.explained_variance_ratio_.sum())vectorizer = TfidfVectorizer()Z = vectorizer.fit_transform(data_csv_clean_list)clustering = DBSCAN(eps=0.68, min_samples=5, metric= "cosine")labels = clustering.fit_predict(Z)pca = TruncatedSVD(n_components=3)Z_downsample = pca.fit_transform(Z)df1 = pd.DataFrame(data = {"x": Z_downsample[:, 0],"y": Z_downsample[:, 1],"z": Z_downsample[:, 2],"color": clustering.labels_,"text": data_csv_clean_list})fig = px.scatter_3d(df1, x="x", y="y", z="z", color="color",size=[1] * len(df1), hover_data="text", opacity=1)fig.show()



55Название файла: TestFileGenerator.pyfrom datetime import dateimport randomfrom random import randint, choiceimport sysimport timeimport fakerfrom datetime import datetimeimport osimport csvos.environ['TZ'] = 'Asia/Kolkata'fak = faker.Faker()

def str_time_prop(start, end, format, prop):stime = time.mktime(time.strptime(start, format))etime = time.mktime(time.strptime(end, format))ptime = stime + prop * (etime - stime)return time.strftime(format, time.localtime(ptime))

def random_date(start, end, prop):return str_time_prop(start, end, '%d/%b/%Y:%I:%M:%S %z', prop)



dictionary = {'request': ['GET', 'POST', 'PUT', 'DELETE'],'endpoint': ['/usr', '/usr/admin', '/usr/admin/de-veloper', '/usr/login', '/usr/register'],'statuscode': ['303', '404', '500', '403', '502','304','200'],'username':['james','adam','eve','alex','smith', 'isabella', 'david', 'angela', 'donald', 'hilary'],'ua' : ['Mozilla/5.0 (Windows NT 10.0; Win64; x64;rv:84.0) Gecko/20100101 Firefox/84.0','Mozilla/5.0 (Android 10; Mobile; rv:84.0) Gecko/84.0Firefox/84.0','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWeb-Kit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',

56'Mozilla/5.0 (Linux; Android 10; ONEPLUS A6000) Ap-pleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Mobile Sa-fari/537.36','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWeb-Kit/537.36(KHTML,likeGecko)Chrome/89.0.4380.0Safari/537.36Edg/89.0.759.0','Mozilla/5.0 (Linux; Android 10; ONEPLUS A6000) Ap-pleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.116 Mobile Sa-fari/537.36 EdgA/45.12.4.5121','Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWeb-Kit/537.36(KHTML,likeGecko)Chrome/87.0.4280.88Safari/537.36OPR/73.0.3856.329','Mozilla/5.0 (Linux; Android 10; ONEPLUS A6000) Ap-pleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Mobile Sa-fari/537.36 OPR/61.2.3076.56749','Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) Ap-pleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A','Mozilla/5.0 (iPhone; CPU iPhone OS 12_4_9 like Mac OSX) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.1.2 Mobile/15E148Safari/604.1'],'referrer' : ['-',fak.uri()]}

f = open("logfiles.log","w")c = open("logfiles.csv", "w")writer = csv.writer(c)head = ["IP", "DATE", "REQUEST", "ENDPOINT", "STATUSCODE", "SIZEOF RESPONSE", "FAKE URL", "USER AGENT", "BYTES TRANSFERRED"]writer.writerow(head)for _ in range(1,10000):IP = fak.ipv4()DATE=random_date("01/Jan/2018:12:00:00+0530","01/Jan/2020:12:00:00 +0530",10)REQUEST = choice(dictionary['request'])ENDPOINT = choice(dictionary['endpoint'])STATUSCODE = choice(dictionary['statuscode'])SIZE_OF_RESPONSE = str(int(random.gauss(5000,50)))#FAKE_URL = choice(dictionary['referrer'])FAKE_URL = fak.uri()USER_AGENT = choice(dictionary['ua'])

57BYTES_TRANSFERRED = random.randint(1,5000)row = [IP, DATE, REQUEST, ENDPOINT, STATUSCODE, SIZE_OF_RE-SPONSE, FAKE_URL, USER_AGENT, BYTES_TRANSFERRED]f.write('%s - - [%s] "%s %s HTTP/1.0" %s %s "%s" "%s" %s\n' %(IP, DATE, REQUEST, ENDPOINT, STATUSCODE, SIZE_OF_RESPONSE, FAKE_URL,USER_AGENT, BYTES_TRANSFERRED))writer.writerow(row)c.close()f.close()



